<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>机器学习笔记-回顾几种线性模型 | Beader&#39;s blog</title>
  <meta name="author" content="beader">
  
  <meta name="description" content="something about Statistics, Data Mining and R">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="机器学习笔记-回顾几种线性模型"/>
  <meta property="og:site_name" content="Beader&#39;s blog"/>

  
    <meta property="og:image" content="undefined"/>
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="Beader&#39;s blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  
  
    <!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

  
</head>


<body>
  <header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">Beader&#39;s blog</a></h1>
  <h2><a href="/">something about Statistics, Data Mining and R</a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
      <li><a href="/about">关于</a></li>
    
    <li><a href="/atom.xml">RSS</a></li>
    <li> <a title="把这个链接拖到你的Chrome收藏夹工具栏中" href='javascript:(function() {
	function c() {
		var e = document.createElement("link");
		e.setAttribute("type", "text/css");
		e.setAttribute("rel", "stylesheet");
		e.setAttribute("href", f);
		e.setAttribute("class", l);
		document.body.appendChild(e)
	}
 
	function h() {
		var e = document.getElementsByClassName(l);
		for (var t = 0; t < e.length; t++) {
			document.body.removeChild(e[t])
		}
	}
 
	function p() {
		var e = document.createElement("div");
		e.setAttribute("class", a);
		document.body.appendChild(e);
		setTimeout(function() {
			document.body.removeChild(e)
		}, 100)
	}
 
	function d(e) {
		return {
			height : e.offsetHeight,
			width : e.offsetWidth
		}
	}
 
	function v(i) {
		var s = d(i);
		return s.height > e && s.height < n && s.width > t && s.width < r
	}
 
	function m(e) {
		var t = e;
		var n = 0;
		while (!!t) {
			n += t.offsetTop;
			t = t.offsetParent
		}
		return n
	}
 
	function g() {
		var e = document.documentElement;
		if (!!window.innerWidth) {
			return window.innerHeight
		} else if (e && !isNaN(e.clientHeight)) {
			return e.clientHeight
		}
		return 0
	}
 
	function y() {
		if (window.pageYOffset) {
			return window.pageYOffset
		}
		return Math.max(document.documentElement.scrollTop, document.body.scrollTop)
	}
 
	function E(e) {
		var t = m(e);
		return t >= w && t <= b + w
	}
 
	function S() {
		var e = document.createElement("audio");
		e.setAttribute("class", l);
		e.src = i;
		e.loop = false;
		e.addEventListener("canplay", function() {
			setTimeout(function() {
				x(k)
			}, 500);
			setTimeout(function() {
				N();
				p();
				for (var e = 0; e < O.length; e++) {
					T(O[e])
				}
			}, 15500)
		}, true);
		e.addEventListener("ended", function() {
			N();
			h()
		}, true);
		e.innerHTML = " <p>If you are reading this, it is because your browser does not support the audio element. We recommend that you get a new browser.</p> <p>";
		document.body.appendChild(e);
		e.play()
	}
 
	function x(e) {
		e.className += " " + s + " " + o
	}
 
	function T(e) {
		e.className += " " + s + " " + u[Math.floor(Math.random() * u.length)]
	}
 
	function N() {
		var e = document.getElementsByClassName(s);
		var t = new RegExp("\\b" + s + "\\b");
		for (var n = 0; n < e.length; ) {
			e[n].className = e[n].className.replace(t, "")
		}
	}
 
	var e = 30;
	var t = 30;
	var n = 350;
	var r = 350;
	var i = "//s3.amazonaws.com/moovweb-marketing/playground/harlem-shake.mp3";
	var s = "mw-harlem_shake_me";
	var o = "im_first";
	var u = ["im_drunk", "im_baked", "im_trippin", "im_blown"];
	var a = "mw-strobe_light";
	var f = "//s3.amazonaws.com/moovweb-marketing/playground/harlem-shake-style.css";
	var l = "mw_added_css";
	var b = g();
	var w = y();
	var C = document.getElementsByTagName("*");
	var k = null;
	for (var L = 0; L < C.length; L++) {
		var A = C[L];
		if (v(A)) {
			if (E(A)) {
				k = A;
				break
			}
		}
	}
	if (A === null) {
		console.warn("Could not find a node of the right size. Please try a different page.");
		return
	}
	c();
	S();
	var O = [];
	for (var L = 0; L < C.length; L++) {
		var A = C[L];
		if (v(A)) {
			O.push(A)
		}
	}
})()    '>High一下</a> </li>
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper"><article class="post">
  
    <div class="gallery">
  <div class="photoset">
    
      <img src="">
    
  </div>
  <div class="control">
    <div class="prev"></div>
    <div class="next"></div>
  </div>
</div>
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2014-08-10T05:00:00.000Z"><a href="/2014/08/10/linear-model/">8月 10 2014</a></time>
      
      
  
    <h1 class="title">机器学习笔记-回顾几种线性模型</h1>
  

    </header>
    <div class="entry">
      
        <p>笔记整理自台大林轩田老师的开放课程-<a href="https://www.coursera.org/course/ntumlone" target="_blank" rel="external">机器学习基石</a>，笔记中所有图片来自于课堂讲义。</p>
<p>&emsp;&emsp;前面的笔记介绍了三种线性模型，<a href="http://beader.me/2013/12/21/perceptron-learning-algorithm/" target="_blank" rel="external">PLA</a>、<a href="http://beader.me/2014/03/09/linear-regression/" target="_blank" rel="external">Linear Regression</a>与<a href="http://beader.me/2014/05/03/logistic-regression/" target="_blank" rel="external">Logistic Regression</a>。之所以称他们是线性模型，是因为这三种分类模型的方程中，都含有一个相同的部分，该部分是各个特征的一个线性组合，也可以称这个部分叫做线性评分方程:</p>
<p>$$\color{purple}{s}=w^Tx$$</p>
<a id="more"></a>

<h2 id="回顾三种线性模型">回顾三种线性模型</h2>
<p>&emsp;&emsp;严谨一点来说，PLA并不是一种“模型”，PLA (Perceptron Learning Algorithm) 是一种“算法”，用来寻找在“线性可分”的情况下，能够把两个类别完全区分开来的一条直线，所以我们简单的把PLA对应的那个模型就叫做Linear Classification。</p>
<p>&emsp;&emsp;下面对比下这三种模型:</p>
<p><img src="/imgs/linear-model/llloverview.png" alt="" title="llloverview.png"></p>
<ul>
<li>Linear Classification模型：取$\color{purple}{s}$的符号作为结果输出，使用0/1 error作为误差衡量方式，但它的cost function，也就是$E_{in}(w)$是一个离散的方程，并且该方程的最优化是一个NP-hard问题（简单说就是非常难解的问题）。</li>
<li>Linear Regression模型：直接输出评分方程，使用平方误差square error作为误差衡量方式，好处是其$E_{in}(w)$是一个凸二次曲线，非常方便求最优解(可通过矩阵运算一次得到结果)。</li>
<li>Logistic Regression模型：输出的是评分方程经过sigmoid的结果，使用cross-entropy作为误差衡量方式，其$E_{in}(w)$是一个凸函数，可以使用gradient descent的方式求最佳解。</li>
</ul>
<p>&emsp;&emsp;Linear Regression和Logistic Regression的输出是一个实数，而不是一个Binary的值，他们能用来解分类问题吗？可以，只要定一个阈值，高于阈值的输出+1，低于阈值的输出-1就好。既然Linear Regression和Logistic Regression都可以用来解分类问题，并且在最优化上，他们都比Linear Classification简单许多，我们能否使用这两个模型取代Linear Classification呢？</p>
<p>&emsp;&emsp;三个模型的区别在于误差的衡量，误差的衡量可以说是一个模型最重要的部分，这部分内容可以参考<a href="Noise%20and%20Error">Noise and Error</a>。</p>
<p><img src="/imgs/linear-model/lll_error_function.png" alt="" title="lll_error_function.png"></p>
<p>&emsp;&emsp;这里$y$是一个binary的值，要么是-1，要么是+1。注意到三个模型的error function都有一个$\color{blue}{y}\color{purple}{s}$的部分，也叫做分类正确性分数 (classification correctness score)。其中$\color{purple}{s}$是模型对某个样本给出的分数，$\color{blue}{y}$是该样本的真实值。</p>
<p>&emsp;&emsp;不难看出，当$\color{blue}{y}=+1$时，我们希望$\color{purple}{s}$越大越好，当$\color{blue}{y}=-1$时，我们希望$\color{purple}{s}$越小越好，所以总的来说，我们希望$\color{blue}{y}\color{purple}{s}$尽可能大。因此这里希望给较小的$\color{blue}{y}\color{purple}{s}$较大的cost，给较大的$\color{blue}{y}\color{purple}{s}$较小的cost即可。因此，不同模型的本质差异，就在于这个cost该怎么给。</p>
<p>&emsp;&emsp;既然这三个error function都与$\color{blue}{y}\color{purple}{s}$有关，我们可以以$\color{blue}{y}\color{purple}{s}$为横坐标，$err$为纵坐标，把这三个函数画出来。</p>
<p><img src="/imgs/linear-model/lll_error_function_vis.png" alt="" title="lll_error_function_vis.png"></p>
<p>&emsp;&emsp;sqr (squre error)为Linear Regression的误差函数，ce (cross entropy)为Logistic Regression的误差函数。可以看出，$\color{red}{err_{sqr}}$在$\color{blue}{y}\color{purple}{s}$较小的时候很大，但是，在$\color{blue}{y}\color{purple}{s}$较大的时候$\color{red}{err_{sqr}}$同样很大，这点不是很理想，因为我们希望$\color{blue}{y}\color{purple}{s}$大的时候cost要小，尽管如此，至少在$\color{red}{err_{sqr}}$小的时候，$\color{blue}{err_{0/1}}$也很小，因此可以拿来做error function。$err_{ce}$则是一个单调递减的函数，形态有点点像$\color{blue}{err_{0/1}}$，但来的比较平缓。注意到$err_{ce}$有一部分是小于$\color{blue}{err_{0/1}}$的，我们希望$err_{ce}$能成为$\color{blue}{err_{0/1}}$的一个upper bound（目的一会儿会说到），只要将$err_{ce}$做一个换底的动作，即：</p>
<p>$$\color{orange}{\text{scaled}}\text{ ce : err}_{\color{orange}{s}ce}(\color{purple}{s},\color{purple}{y})=\color{orange}{log_2}(1+exp(-\color{purple}{ys}))$$</p>
<p><img src="/imgs/linear-model/lll_error_function_scale.png" alt="" title="lll_error_function_scale.png"></p>
<p>&emsp;&emsp;事实上这里做scale的动作并不会影响最优化的过程，它只是让之后的推导证明更加容易一些。</p>
<p>&emsp;&emsp;现在稍稍回忆一下我们的问题是什么:</p>
<p>&emsp;&emsp;能不能拿Linear Regression或Logistic Regression来替代Linear Classification？</p>
<p>&emsp;&emsp;为什么会想做这样的替代？Linear Classification，在分类这件事上，它做的很好，但在最优化这件事上，由于是NP-hard问题，不大好做，而Linear Regression与Logistic Regression在最优化上比较容易。因此，如果他们在分类能力上的表现能够接近Linear Classification，用他们来替代Linear Classification来处理分类的问题，就是件皆大欢喜的事。这时候就可以想想刚刚为何要把$err_se$ scale 成$err_{0/1}$的upper bound，目的就是为了让这几个模型的观点在某个方向上是一致的，即：</p>
<p>&emsp;&emsp;$\color{red}{err_{sqr}}$/$err_{sce}$低的时候，$\color{blue}{err_{0/1}}$也低</p>
<p>&emsp;&emsp;通俗一点讲：</p>
<p>&emsp;&emsp;假设某种疾病有两种检测方法A和B。A方法检查结果为阳性时，则患病，为阴性时，则未患病。B方法的效率差一些，对于一部分患病的人，B方法不一定结果为阳性，但只要B的结果为阳性，再用A来检查，A的结果一定也为阳性。这么一来，我们就可以说，如果B方法的结果为阳性的时候，我们就没有必要使用A方法再检查一次了，它的效率是和A相同的。</p>
<p>&emsp;&emsp;再通俗一点讲：</p>
<p>&emsp;&emsp;如果使用$\color{red}{err_{sqr}}$/$err_{sce}$来衡量一个模型分类分得好不好的时候，如果他们认为分得好，那么如果使用$\color{blue}{err_{0/1}}$，它也会认为分得好。</p>
<p>&emsp;&emsp;对比下在处理分类问题时，使用PLA，Linear Regression以及Logistic Regression的优缺点。</p>
<p>&emsp;&emsp;<strong>PLA</strong>:  </p>
<ul>
<li>优点：数据是线性可分时，$E_{in}^{0/1}$保证可以降到最低</li>
<li>缺点：数据不是线性可分时，要额外使用pocket技巧，较难做最优化</li>
</ul>
<p>&emsp;&emsp;<strong>Linear Regression</strong>:  </p>
<ul>
<li>优点：在这三个模型中最容易做最优化</li>
<li>缺点：在$\color{blue}{y}\color{purple}{s}$很大或很小时，这个bound是很宽松的，意思就是没有办法保证$E_{in}^{0/1}$能够很小</li>
</ul>
<p>&emsp;&emsp;<strong>Logistic Regression</strong>:  </p>
<ul>
<li>优点：较容易最优化</li>
<li>缺点：当$\color{blue}{y}\color{purple}{s}$是很小的负数时，bound很宽松</li>
</ul>
<p>&emsp;&emsp;所以我们常常可以使用Linear Regresion跑出的$w$作为(PLA/Pocket/Logistic Regression)的$w_0$，然后再使用$w_0$来跑其他模型，这样可以加快其他模型的最优化速度。同时，由于拿到的数据常常是线性不可分的，我们常常会去使用Logistic Regression而不是PLA+pocket。</p>
<h2 id="Stochastic_Gradient_Descent">Stochastic Gradient Descent</h2>
<p>&emsp;&emsp;我们知道PLA与Logistic Regression都是通过迭代的方式来实现最优化的，即：</p>
<p>&emsp;&emsp;For t = 0, 1, …<br>$$w_{t+1}\leftarrow w_t + \eta v$$<br>&emsp;&emsp;when stop, return last w as g</p>
<p>&emsp;&emsp;区别在于，PLA每次迭代只需要针对一个点进行错误修正，而Logistic Regression每一次迭代都需要计算每一个点对于梯度的贡献，再把他们平均起来:</p>
<p><img src="/imgs/linear-model/pla_logistic_opt.png" alt="" title="pla_logistic_opt.png"></p>
<p>&emsp;&emsp;这样一来，数据量大的时候，由于需要计算每一个点，Logistic Regerssion就会很慢了。<a href="http://beader.me/2014/05/03/logistic-regression/" target="_blank" rel="external">上一篇</a>有讲到Logistic Regression每次是怎样迭代的：</p>
<script type="math/tex; mode=display">
w_{t+1} \leftarrow w_t + \eta \underbrace{\color{red}{\frac{1}{N}\sum_{n=1}^{N}}\color{purple}{\theta(\color{black}{-y_nw_t^Tx_n})}\color{orange}{(y_nx_n)}}_{-\color{blue}{\triangledown E_{in}(w_t)}}
</script>

<p>&emsp;&emsp;那么我可以不可以每次只看一个点，即不要公式中先求和再取平均数的那个部分呢？随机取一个点n，它对梯度的贡献为:<br>$$\color{orange}{\triangledown _w err(w,x_n,y_n)}$$</p>
<p>&emsp;&emsp;我们把它称为随机梯度，stochastic gradient。而真实的梯度，可以认为是随机抽出一个点的梯度值的期望(红色部分取平均数的动作):</p>
<script type="math/tex; mode=display">
\triangledown_w E_{in}(w) = \color{red}{\underset{random\,n}{\epsilon}}\triangledown_w \color{orange}{err(w,x_n,y_n)}
</script>

<p>&emsp;&emsp;因此我们可以把随机梯度当成是在真实梯度上增加一个均值为0的noise：<br>$$\color{orange}{\text{stochastic gradient}} = \color{blue}{\text{true gradient}} + \color{red}{\text{zero-mean ‘noise’ directions}}$$</p>
<p>&emsp;&emsp;虽然和true gradient存在一定的误差，但是可以认为在足够多的迭代次数之后，也能达到差不多好的结果。我们把这种方法成为随机梯度下降，Stochastic Gradient Descent (SGD):</p>
<script type="math/tex; mode=display">
w_{t+1} \leftarrow w_t + \eta \underbrace{\color{purple}{\theta(\color{black}{-y_nw_t^Tx_n})}\color{orange}{(y_nx_n)}}_{-\color{blue}{\triangledown_{err}(w_t,x_n,y_n)}}
</script>

<p>&emsp;&emsp;和之前说到的Gradient Descent相比，SGD的好处在于时间复杂度大幅减小(每次只随机地看一个点)，在数据量很大的时候可以很快得得到结果，当然缺点就是，如果前面说到的那个$\color{red}{\text{noise}}$很大的话，会稍稍有点不稳定。</p>
<h2 id="多类别分类">多类别分类</h2>
<p>&emsp;&emsp;我们现在已经有办法使用线性分类器解决二元分类问题，但有的时候，我们需要对多个类别进行分类，即模型的输出不再是0和1两种，而会是多个不同的类别。那么如何套用二元分类的方法来解决多类别分类的问题呢？</p>
<p>&emsp;&emsp;利用二元分类器来解决多类别分类问题主要有两种策略，OVA(One vs. ALL)和OVO(One vs. One)。</p>
<p>&emsp;&emsp;先来看看OVA，假设原问题有四个类别，那么每次我把其中一个类别当成圈圈，其他所有类别当成叉叉，建立二元分类器，循环下去，最终我们会得到4个分类器。</p>
<p><img src="/imgs/linear-model/ova.png" alt="" title="ova.png"></p>
<p>&emsp;&emsp;做预测的时候，分别使用这四个分类器进行预测，预测为圈圈的那个模型所代表的类别，即为最终的输出。譬如正方形的那个分类器输出圈圈，菱形、三角形、星型这三个分类器都说是叉叉，则我们认为它是正方形。当然这里可能遇到一个问题，就是所有模型都说不是自己的时候(都输出叉叉)，怎么办？<br>&emsp;&emsp;很简单，只要让各个分类器都输出是否为自己类别的概率值，即可，然后选择概率值最高的那个分类器所对应的类别，作为最终的输出。</p>
<p>&emsp;&emsp;在类别较多的时候，如果使用OVA方法，则又会遇到数据不平衡(unbalance)的问题，你拿一个类别作为圈圈，其他所有类别作为叉叉，那么圈圈的比例就会非常小，而叉叉的比例非常高。为了解决这个不平衡的问题，我们可以利用另外一个策略，OVO，即每次只拿两个类别的数据出来建建立分类器，如下图。</p>
<p><img src="/imgs/linear-model/ovo.png" alt="" title="ovo.png"></p>
<p>&emsp;&emsp;这个想法类似在打比赛，一笔新数据进来之后，分别使用这六个模型进行预测，得票数最多的那个类别，作为最终的输出。这样做的好处是，有效率，每次只拿两个类别的数据进行训练，每个模型训练数据量要少很多。但是缺点是，由于模型的数量增加了，将消耗更多的存储空间，会减慢预测的速度。</p>

      
    </div>
    <footer>
      
        
        
  
  <div class="tags">
    <a href="/tags/pla/">pla</a>, <a href="/tags/线性回归(Linear-Regression)/">线性回归(Linear Regression)</a>, <a href="/tags/Logistic-Regression/">Logistic Regression</a>
  </div>

        
  <div class="addthis addthis_toolbox addthis_default_style">
    
      <a class="addthis_button_facebook_like" fb:like:layout="button_count"></a>
    
    
      <a class="addthis_button_tweet"></a>
    
    
      <a class="addthis_button_google_plusone" g:plusone:size="medium"></a>
    
    
      <a class="addthis_button_pinterest_pinit" pi:pinit:layout="horizontal"></a>
    
    <a class="addthis_counter addthis_pill_style"></a>
  </div>
  <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js"></script>



  喜欢就分享一下吧
  <div class="bdsharebuttonbox">
  
    <a href="#" class="bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
  
  
    <a href="#" class="bds_tqq" data-cmd="tqq" title="分享到腾讯微博"></a>
  
  
    <a href="#" class="bds_renren" data-cmd="renren" title="分享到人人网"></a>
  
  
    <a href="#" class="bds_weixin" data-cmd="weixin" title="分享到微信"></a>
  
  
    <a href="#" class="bds_douban" data-cmd="douban" title="分享到豆瓣网"></a>
  
  
</div>
  <script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"2","bdPic":"","bdStyle":"0","bdSize":"16"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];</script>

      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>


<section id="comment">

<!-- Duoshuo Comment BEGIN -->
<div class="ds-thread"></div>
<script type="text/javascript">
  var duoshuoQuery = {short_name:"beader"};
  (function() {
 	var ds = document.createElement('script');
	ds.type = 'text/javascript';ds.async = true;
	ds.src = 'http://static.duoshuo.com/embed.js';
	ds.charset = 'UTF-8';
	(document.getElementsByTagName('head')[0] 
	|| document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
</script>
<!-- Duoshuo Comment END -->

</section>

</div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="搜索">
    <input type="hidden" name="q" value="site:beader.me">
  </form>
</div>

  <div class="widget tag">
<h3 class="title">整理</h3>
<ul class="entry">
<li><a href="http://beader.me/mlnotebook/" title="Machine Learning Notebook">机器学习笔记(Open Book)</a></li>
</ul>
</div>

  

  
<div class="widget tag">
  <h3 class="title">标签</h3>
  <ul class="entry">
  
    <li><a href="/tags/Error-Measure/">Error Measure</a><small>1</small></li>
  
    <li><a href="/tags/Hoeffding’s-Inequality/">Hoeffding’s Inequality</a><small>1</small></li>
  
    <li><a href="/tags/Logistic-Regression/">Logistic Regression</a><small>2</small></li>
  
    <li><a href="/tags/Machine-Learning/">Machine Learning</a><small>7</small></li>
  
    <li><a href="/tags/MapReduce/">MapReduce</a><small>1</small></li>
  
    <li><a href="/tags/Noise/">Noise</a><small>1</small></li>
  
    <li><a href="/tags/ODPS/">ODPS</a><small>1</small></li>
  
    <li><a href="/tags/R/">R</a><small>3</small></li>
  
    <li><a href="/tags/VC-Dimension，成长函数-(growth-function)/">VC Dimension，成长函数 (growth function)</a><small>2</small></li>
  
    <li><a href="/tags/VC-Dimension，自由度(degree-of-freedom)/">VC Dimension，自由度(degree of freedom)</a><small>1</small></li>
  
    <li><a href="/tags/auc/">auc</a><small>1</small></li>
  
    <li><a href="/tags/classification-tree/">classification tree</a><small>1</small></li>
  
    <li><a href="/tags/ggplot2/">ggplot2</a><small>1</small></li>
  
    <li><a href="/tags/gini-coefficient/">gini coefficient</a><small>1</small></li>
  
    <li><a href="/tags/human-activity-recognition/">human activity recognition</a><small>1</small></li>
  
    <li><a href="/tags/pla/">pla</a><small>2</small></li>
  
    <li><a href="/tags/plyr/">plyr</a><small>1</small></li>
  
    <li><a href="/tags/r/">r</a><small>1</small></li>
  
    <li><a href="/tags/random-forest/">random forest</a><small>2</small></li>
  
    <li><a href="/tags/rcurl/">rcurl</a><small>1</small></li>
  
    <li><a href="/tags/roc/">roc</a><small>1</small></li>
  
    <li><a href="/tags/text-mining/">text mining</a><small>1</small></li>
  
    <li><a href="/tags/word-cloud/">word cloud</a><small>1</small></li>
  
    <li><a href="/tags/偏导数-(partial-derivative)/">偏导数 (partial derivative)</a><small>1</small></li>
  
    <li><a href="/tags/分类器/">分类器</a><small>1</small></li>
  
    <li><a href="/tags/帽子矩阵(Hat-Matrix)/">帽子矩阵(Hat Matrix)</a><small>1</small></li>
  
    <li><a href="/tags/感知机-(perceptron)/">感知机 (perceptron)</a><small>1</small></li>
  
    <li><a href="/tags/梯度下降-(gradient-decent)/">梯度下降 (gradient decent)</a><small>1</small></li>
  
    <li><a href="/tags/线性回归(Linear-Regression)/">线性回归(Linear Regression)</a><small>2</small></li>
  
    <li><a href="/tags/统计图表/">统计图表</a><small>1</small></li>
  
    <li><a href="/tags/非线性转换(Nonlinear-Transformation)/">非线性转换(Nonlinear Transformation)</a><small>1</small></li>
  
  </ul>
</div>


  <div class="widget tag">
<h3 class="title">友情链接</h3>
<ul class="entry">
<li><a href="http://lemoner.me//" title="Lemon's Blog">Lemon's Blog</a></li>
</ul>
</div>
</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2014 beader
  
</div>
<div class="clearfix"></div></footer>
  <script src="//cdnjscn.b0.upaiyun.com/libs/jquery/2.0.3/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>


<script type="text/javascript">
var disqus_shortname = 'beader';

(function(){
  var dsq = document.createElement('script');
  dsq.type = 'text/javascript';
  dsq.async = true;
  dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
  (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
}());
</script>



<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>




<script type="text/javascript">
var _bdhmProtocol = (("https:" == document.location.protocol) ? " https://" : " http://");
document.write(unescape("%3Cscript src='" + _bdhmProtocol + "hm.baidu.com/h.js%3F96088bf0972512652719efc549bd275b' type='text/javascript'%3E%3C/script%3E"));
</script>


</body>
</html>