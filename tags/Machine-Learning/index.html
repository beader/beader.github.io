<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Machine Learning | Beader&#39;s blog</title>
  <meta name="author" content="beader">
  
  <meta name="description" content="something about Statistics, Data Mining and R">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
  <meta property="og:site_name" content="Beader&#39;s blog"/>

  
    <meta property="og:image" content="undefined"/>
  

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="Beader&#39;s blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  <% if (theme.google_analytics){ %>
<script type="text/javascript">
  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', '<%= theme.google_analytics %>']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>
<% } %>
  
    <!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

  
</head>


<body>
  <header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">Beader&#39;s blog</a></h1>
  <h2><a href="/">something about Statistics, Data Mining and R</a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
      <li><a href="/about">关于</a></li>
    
    <li><a href="/atom.xml">RSS</a></li>
    <li> <a title="把这个链接拖到你的Chrome收藏夹工具栏中" href='javascript:(function() {
	function c() {
		var e = document.createElement("link");
		e.setAttribute("type", "text/css");
		e.setAttribute("rel", "stylesheet");
		e.setAttribute("href", f);
		e.setAttribute("class", l);
		document.body.appendChild(e)
	}
 
	function h() {
		var e = document.getElementsByClassName(l);
		for (var t = 0; t < e.length; t++) {
			document.body.removeChild(e[t])
		}
	}
 
	function p() {
		var e = document.createElement("div");
		e.setAttribute("class", a);
		document.body.appendChild(e);
		setTimeout(function() {
			document.body.removeChild(e)
		}, 100)
	}
 
	function d(e) {
		return {
			height : e.offsetHeight,
			width : e.offsetWidth
		}
	}
 
	function v(i) {
		var s = d(i);
		return s.height > e && s.height < n && s.width > t && s.width < r
	}
 
	function m(e) {
		var t = e;
		var n = 0;
		while (!!t) {
			n += t.offsetTop;
			t = t.offsetParent
		}
		return n
	}
 
	function g() {
		var e = document.documentElement;
		if (!!window.innerWidth) {
			return window.innerHeight
		} else if (e && !isNaN(e.clientHeight)) {
			return e.clientHeight
		}
		return 0
	}
 
	function y() {
		if (window.pageYOffset) {
			return window.pageYOffset
		}
		return Math.max(document.documentElement.scrollTop, document.body.scrollTop)
	}
 
	function E(e) {
		var t = m(e);
		return t >= w && t <= b + w
	}
 
	function S() {
		var e = document.createElement("audio");
		e.setAttribute("class", l);
		e.src = i;
		e.loop = false;
		e.addEventListener("canplay", function() {
			setTimeout(function() {
				x(k)
			}, 500);
			setTimeout(function() {
				N();
				p();
				for (var e = 0; e < O.length; e++) {
					T(O[e])
				}
			}, 15500)
		}, true);
		e.addEventListener("ended", function() {
			N();
			h()
		}, true);
		e.innerHTML = " <p>If you are reading this, it is because your browser does not support the audio element. We recommend that you get a new browser.</p> <p>";
		document.body.appendChild(e);
		e.play()
	}
 
	function x(e) {
		e.className += " " + s + " " + o
	}
 
	function T(e) {
		e.className += " " + s + " " + u[Math.floor(Math.random() * u.length)]
	}
 
	function N() {
		var e = document.getElementsByClassName(s);
		var t = new RegExp("\\b" + s + "\\b");
		for (var n = 0; n < e.length; ) {
			e[n].className = e[n].className.replace(t, "")
		}
	}
 
	var e = 30;
	var t = 30;
	var n = 350;
	var r = 350;
	var i = "//s3.amazonaws.com/moovweb-marketing/playground/harlem-shake.mp3";
	var s = "mw-harlem_shake_me";
	var o = "im_first";
	var u = ["im_drunk", "im_baked", "im_trippin", "im_blown"];
	var a = "mw-strobe_light";
	var f = "//s3.amazonaws.com/moovweb-marketing/playground/harlem-shake-style.css";
	var l = "mw_added_css";
	var b = g();
	var w = y();
	var C = document.getElementsByTagName("*");
	var k = null;
	for (var L = 0; L < C.length; L++) {
		var A = C[L];
		if (v(A)) {
			if (E(A)) {
				k = A;
				break
			}
		}
	}
	if (A === null) {
		console.warn("Could not find a node of the right size. Please try a different page.");
		return
	}
	c();
	S();
	var O = [];
	for (var L = 0; L < C.length; L++) {
		var A = C[L];
		if (v(A)) {
			O.push(A)
		}
	}
})()    '>High一下</a> </li>
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper">
<h2 class="archive-title tag">Machine Learning</h2>


  
    <article class="post">
  
    <div class="gallery">
  <div class="photoset">
    
      <img src="">
    
  </div>
  <div class="control">
    <div class="prev"></div>
    <div class="next"></div>
  </div>
</div>
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2014-05-03T08:00:00.000Z"><a href="/2014/05/03/logistic-regression/">5月 3 2014</a></time>
      
      
  
    <h1 class="title"><a href="/2014/05/03/logistic-regression/">机器学习笔记-Logistic Regression</a></h1>
  

    </header>
    <div class="entry">
      
        <p>笔记整理自台大林轩田老师的开放课程-<a href="https://www.coursera.org/course/ntumlone" target="_blank" rel="external">机器学习基石</a>，笔记中所有图片来自于课堂讲义。</p>
<p>&emsp;&emsp;<a href="http://beader.me/2014/03/09/linear-regression/" target="_blank" rel="external">上一篇</a>比较深入地去理解了线性回归的思想和算法。分类和回归是机器学习中很重要的两大内容。而本篇要讲的Logistic Regression，名字上看是回归，但实际上却又和分类有关。</p>
<p>&emsp;&emsp;之前提过的二元分类器如PLA，其目标函数为， $f(x)=sign(w^Tx)\in{-1,+1}$，输出要么是-1要么是+1，是一个“硬”的分类器。而Logistic Regression是一个“软”的分类器，它的输出是$y=+1$的概率，因此Logistic Regression的目标函数是 $\color{purple}{f}(x)=\color{orange}{P(+1|x)}\in [0,1]$。</p>
<p>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/2014/05/03/logistic-regression/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>



  
    <article class="post">
  
    <div class="gallery">
  <div class="photoset">
    
      <img src="">
    
  </div>
  <div class="control">
    <div class="prev"></div>
    <div class="next"></div>
  </div>
</div>
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2014-03-09T06:00:00.000Z"><a href="/2014/03/09/linear-regression/">3月 9 2014</a></time>
      
      
  
    <h1 class="title"><a href="/2014/03/09/linear-regression/">机器学习笔记-Linear Regression</a></h1>
  

    </header>
    <div class="entry">
      
        <p>笔记整理自台大林轩田老师的开放课程-<a href="https://www.coursera.org/course/ntumlone" target="_blank" rel="external">机器学习基石</a>，笔记中所有图片来自于课堂讲义。</p>
<p>&emsp;&emsp;向所有坚持用$\LaTeX$手打公式而不是直接使用截图的偏执狂致敬！</p>

      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/2014/03/09/linear-regression/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>



  
    <article class="post">
  
    <div class="gallery">
  <div class="photoset">
    
      <img src="">
    
  </div>
  <div class="control">
    <div class="prev"></div>
    <div class="next"></div>
  </div>
</div>
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2014-03-02T06:00:00.000Z"><a href="/2014/03/02/noise-and-error/">3月 2 2014</a></time>
      
      
  
    <h1 class="title"><a href="/2014/03/02/noise-and-error/">机器学习笔记-Noise and Error</a></h1>
  

    </header>
    <div class="entry">
      
        <p>笔记整理自台大林轩田老师的开放课程-<a href="https://www.coursera.org/course/ntumlone" target="_blank" rel="external">机器学习基石</a>，笔记中所有图片来自于课堂讲义。</p>
<p>&emsp;&emsp;这篇笔记是阐述“为什么机器能够学习”这个话题的最后一篇，林老师用了4周时间在告诉我们什么时候机器可以学习以及机器为什么能够学习，对比<a href="https://www.coursera.org/course/ml" target="_blank" rel="external">Ng</a>的那门课，第4周已经在讲类神经网络了。为什么要花这么大的篇幅来搞清楚这些那么理论的东西呢？原因很简单，Ng那门课教的是剑法招式，而林帮主这门课教的是内功。郭靖当年跟着江南七怪习武10多年，进步缓慢，难有所成，但跟着马钰只学了个呼吸吐纳之术，武功却不自觉突飞猛进，原来难以完成的动作突然可以轻松完成了。想要修得真功夫，欲速则不达，林帮主的良苦用心，不知各位同学能否体会。</p>
<p>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/2014/03/02/noise-and-error/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>



  
    <article class="post">
  
    <div class="gallery">
  <div class="photoset">
    
      <img src="">
    
  </div>
  <div class="control">
    <div class="prev"></div>
    <div class="next"></div>
  </div>
</div>
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2014-02-22T04:00:00.000Z"><a href="/2014/02/22/vc-dimension-three/">2月 22 2014</a></time>
      
      
  
    <h1 class="title"><a href="/2014/02/22/vc-dimension-three/">机器学习笔记-VC Dimension, Part III</a></h1>
  

    </header>
    <div class="entry">
      
        <p>笔记整理自台大林轩田老师的开放课程-<a href="https://www.coursera.org/course/ntumlone" target="_blank" rel="external">机器学习基石</a>，笔记中所有图片来自于课堂讲义。</p>
<p>&emsp;&emsp;<a href="http://beader.me/2014/02/15/vc-dimension-two/" target="_blank" rel="external">上一篇</a>讲到了VC Dimension以及VC Bound。VC Bound所描述的是在给定数据量N以及给定的Hypothesis Set的条件下，遇到坏事情的概率的上界，即$E_{in}$与$E_{out}$差很远的概率，最多是多少。VC Bound用公式表示就是：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathbb{P}[BAD] &= \mathbb{P}[\exists h \in \mathcal{H}\text{ s.t. } |E_{in}(h)-E_{out}(h)|\gt \epsilon] \\\
&\leq 4m_{\mathcal{H}}(2N)exp(-\frac{1}{8}\epsilon^2N)
\end{aligned}
</script>

<p>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/2014/02/22/vc-dimension-three/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>



  
    <article class="post">
  
    <div class="gallery">
  <div class="photoset">
    
      <img src="">
    
  </div>
  <div class="control">
    <div class="prev"></div>
    <div class="next"></div>
  </div>
</div>
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2014-02-15T04:00:00.000Z"><a href="/2014/02/15/vc-dimension-two/">2月 15 2014</a></time>
      
      
  
    <h1 class="title"><a href="/2014/02/15/vc-dimension-two/">机器学习笔记-VC Dimension, Part II</a></h1>
  

    </header>
    <div class="entry">
      
        <p>笔记整理自台大林轩田老师的开放课程-<a href="https://www.coursera.org/course/ntumlone" target="_blank" rel="external">机器学习基石</a>，笔记中所有图片来自于课堂讲义。</p>
<p>&emsp;&emsp;<a href="http://beader.me/2014/01/23/vc-dimension-one/" target="_blank" rel="external">上一篇</a>用成长函数$m_{\mathcal{H}}(N)$来衡量Hypotheses Set $\mathcal{H}$中有效的方程的数量(Effective Number of Hypotheses)，以取代Hoeffding’s Inequality中的大$M$，并用一种间接的方式 —- break point，来寻找$m_{\mathcal{H}}(N)$的上界，从而避免了直接研究$\mathcal{H}$的成长函数的困难。</p>
<p>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/2014/02/15/vc-dimension-two/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>



  
    <article class="post">
  
    <div class="gallery">
  <div class="photoset">
    
      <img src="">
    
  </div>
  <div class="control">
    <div class="prev"></div>
    <div class="next"></div>
  </div>
</div>
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2014-01-23T05:00:00.000Z"><a href="/2014/01/23/vc-dimension-one/">1月 23 2014</a></time>
      
      
  
    <h1 class="title"><a href="/2014/01/23/vc-dimension-one/">机器学习笔记-VC Dimension, Part I</a></h1>
  

    </header>
    <div class="entry">
      
        <p>笔记整理自台大林轩田老师的开放课程-<a href="https://www.coursera.org/course/ntumlone" target="_blank" rel="external">机器学习基石</a>，笔记中所有图片来自于课堂讲义。</p>
<p>&emsp;&emsp;<a href="http://beader.me/2014/01/15/is-learning-feasible/" target="_blank" rel="external">上一篇</a>讲到，learning的时候如果遇上bad sample，如果遇上bad sample我们就无法保证$E_{in}$和$E_{out}$很接近。我们用了一个不等式来衡量遇上bad sample的概率：</p>
<p>$$\mathbb{P}_\mathcal{D}[BAD\ D]\leq 2Mexp(-2\epsilon ^2N)$$</p>
<p>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/2014/01/23/vc-dimension-one/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>



  
    <article class="post">
  
    <div class="gallery">
  <div class="photoset">
    
      <img src="">
    
  </div>
  <div class="control">
    <div class="prev"></div>
    <div class="next"></div>
  </div>
</div>
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2014-01-15T04:00:00.000Z"><a href="/2014/01/15/is-learning-feasible/">1月 15 2014</a></time>
      
      
  
    <h1 class="title"><a href="/2014/01/15/is-learning-feasible/">机器学习笔记-机器为何能够学习?</a></h1>
  

    </header>
    <div class="entry">
      
        <p>笔记整理自台大林轩田老师的开放课程-<a href="https://www.coursera.org/course/ntumlone" target="_blank" rel="external">机器学习基石</a>，笔记中所有图片来自于课堂讲义。</p>
<h2 id="机器学习的基础架构_(Learning_From_Data)">机器学习的基础架构 (Learning From Data)</h2>
<p>&emsp;&emsp;银行在决定是否要通过贷款申请人的授信请求前，会根据申请人的资料对其进行风险评估，(通常银行会为其计算信用评分)，申请人状况符合银行要求时，银行通过其申请，反之则婉拒。那么银行凭借什么来判断申请人将来是否会违约呢？通过银行之前的信用贷款记录，这些记录中，有些客户发生了违约行为，其他则表现良好，银行从这些违约与非违约的记录中learning到了一些规律，然后利用这些规律，来对新申请人的违约风险进行估计。因此信用评估模型就是一个learning的问题，那么我们该如何使用历史数据做好learning呢？</p>
<p>&emsp;&emsp;下面这张图描述了learning的基础架构：</p>
<p><img src="/imgs/is-learning-feasible/basic_setup_of_the_learning_problem.png" alt="" title="basic_setup_of_the _learning_problem.png"><br>
      
    </div>
    <footer>
      
        
          <div class="alignleft">
            <a href="/2014/01/15/is-learning-feasible/#more" class="more-link">Read More</a>
          </div>
        
        
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>



  

  <nav id="pagination">
  
  
  <div class="clearfix"></div>
</nav>
</div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="搜索">
    <input type="hidden" name="q" value="site:beader.me">
  </form>
</div>

  <div class="widget tag">
<h3 class="title">整理</h3>
<ul class="entry">
<li><a href="http://beader.me/mlnotebook/" title="Machine Learning Notebook">机器学习笔记(Open Book)</a></li>
</ul>
</div>

  

  
<div class="widget tag">
  <h3 class="title">标签</h3>
  <ul class="entry">
  
    <li><a href="/tags/Error-Measure/">Error Measure</a><small>1</small></li>
  
    <li><a href="/tags/Hoeffding’s-Inequality/">Hoeffding’s Inequality</a><small>1</small></li>
  
    <li><a href="/tags/Logistic-Regression/">Logistic Regression</a><small>2</small></li>
  
    <li><a href="/tags/Machine-Learning/">Machine Learning</a><small>7</small></li>
  
    <li><a href="/tags/MapReduce/">MapReduce</a><small>1</small></li>
  
    <li><a href="/tags/Noise/">Noise</a><small>1</small></li>
  
    <li><a href="/tags/ODPS/">ODPS</a><small>1</small></li>
  
    <li><a href="/tags/R/">R</a><small>3</small></li>
  
    <li><a href="/tags/VC-Dimension，成长函数-(growth-function)/">VC Dimension，成长函数 (growth function)</a><small>2</small></li>
  
    <li><a href="/tags/VC-Dimension，自由度(degree-of-freedom)/">VC Dimension，自由度(degree of freedom)</a><small>1</small></li>
  
    <li><a href="/tags/auc/">auc</a><small>1</small></li>
  
    <li><a href="/tags/classification-tree/">classification tree</a><small>1</small></li>
  
    <li><a href="/tags/ggplot2/">ggplot2</a><small>1</small></li>
  
    <li><a href="/tags/gini-coefficient/">gini coefficient</a><small>1</small></li>
  
    <li><a href="/tags/human-activity-recognition/">human activity recognition</a><small>1</small></li>
  
    <li><a href="/tags/pla/">pla</a><small>2</small></li>
  
    <li><a href="/tags/plyr/">plyr</a><small>1</small></li>
  
    <li><a href="/tags/r/">r</a><small>1</small></li>
  
    <li><a href="/tags/random-forest/">random forest</a><small>2</small></li>
  
    <li><a href="/tags/rcurl/">rcurl</a><small>1</small></li>
  
    <li><a href="/tags/roc/">roc</a><small>1</small></li>
  
    <li><a href="/tags/text-mining/">text mining</a><small>1</small></li>
  
    <li><a href="/tags/word-cloud/">word cloud</a><small>1</small></li>
  
    <li><a href="/tags/偏导数-(partial-derivative)/">偏导数 (partial derivative)</a><small>1</small></li>
  
    <li><a href="/tags/分类器/">分类器</a><small>1</small></li>
  
    <li><a href="/tags/帽子矩阵(Hat-Matrix)/">帽子矩阵(Hat Matrix)</a><small>1</small></li>
  
    <li><a href="/tags/感知机-(perceptron)/">感知机 (perceptron)</a><small>1</small></li>
  
    <li><a href="/tags/梯度下降-(gradient-decent)/">梯度下降 (gradient decent)</a><small>1</small></li>
  
    <li><a href="/tags/线性回归(Linear-Regression)/">线性回归(Linear Regression)</a><small>2</small></li>
  
    <li><a href="/tags/统计图表/">统计图表</a><small>1</small></li>
  
    <li><a href="/tags/非线性转换(Nonlinear-Transformation)/">非线性转换(Nonlinear Transformation)</a><small>1</small></li>
  
  </ul>
</div>


  <div class="widget tag">
<h3 class="title">友情链接</h3>
<ul class="entry">
<li><a href="http://ytliu.info/" title="McTrain's Blog">McTrain's Blog</a></li>
<li><a href="http://lemoner.me//" title="Lemon's Blog">Lemon's Blog</a></li>
</ul>
</div>
</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2014 beader
  
</div>
<div class="clearfix"></div></footer>
  <script src="//cdnjscn.b0.upaiyun.com/libs/jquery/2.0.3/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>




<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>




<script type="text/javascript">
var _bdhmProtocol = (("https:" == document.location.protocol) ? " https://" : " http://");
document.write(unescape("%3Cscript src='" + _bdhmProtocol + "hm.baidu.com/h.js%3F96088bf0972512652719efc549bd275b' type='text/javascript'%3E%3C/script%3E"));
</script>


</body>
</html>